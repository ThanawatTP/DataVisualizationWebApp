{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "from IPython.display import display\n",
    "\n",
    "# Load data\n",
    "iris = data.iris()\n",
    "\n",
    "# Create chart\n",
    "chart = alt.Chart(iris).mark_circle().encode(\n",
    "    x='petalLength',\n",
    "    y='petalWidth',\n",
    "    color='species'\n",
    ")\n",
    "\n",
    "# Display chart in HTML\n",
    "chart.save('chart.json')\n",
    "display(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data\n",
    "source = data.stocks()\n",
    "chart = (\n",
    "    alt.Chart(source)\n",
    "    .transform_filter(alt.datum.symbol != \"IBM\")\n",
    "    .encode(color=alt.Color(\"symbol\", legend=None))\n",
    ")\n",
    "line = chart.mark_line().encode(x=\"date:T\", y=\"price:Q\")\n",
    "label = chart.encode(\n",
    "    x=alt.X(\"max(date):T\"),\n",
    "    y=alt.Y(\"price:Q\", aggregate=alt.ArgmaxDef(argmax=\"date\")),\n",
    "    text=\"symbol\",\n",
    ")\n",
    "text = label.mark_text(align=\"left\", dx=4)\n",
    "circle = label.mark_circle()\n",
    "chart = line + circle + text\n",
    "chart.save('chart.json')\n",
    "display(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "source = data.stocks()\n",
    "\n",
    "chart = alt.Chart(source).transform_filter(\n",
    "    alt.datum.symbol != 'GOOG'\n",
    ").mark_area().encode(\n",
    "    x='date:T',\n",
    "    y='price:Q',\n",
    "    color='symbol:N',\n",
    "    row=alt.Row('symbol:N', sort=['MSFT', 'AAPL', 'IBM', 'AMZN'])\n",
    ").properties(height=50, width=400)\n",
    "chart.save('chart.json')\n",
    "display(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "data_path = \"../test/covid19data/all_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df.drop(index=df[df[\"province\"].isin([\"ทั้งประเทศ\",\"ไม่ระบุ\"])].index, inplace=True)\n",
    "obj_cols = df.select_dtypes(include=['object']).columns.to_list()\n",
    "int_cols = df.select_dtypes(include=['int']).columns.to_list()\n",
    "\n",
    "Measurement = int_cols[3]\n",
    "Dimension = obj_cols[1]\n",
    "Column = obj_cols[2]\n",
    "\n",
    "chart = alt.Chart(df).mark_bar(clip=True).encode(\n",
    "    x = alt.X(Dimension,type = \"nominal\"),\n",
    "    y = alt.Y(Measurement, \n",
    "              type= \"quantitative\",\n",
    "              scale= alt.Scale(domain=[df[Measurement].min(),df[Measurement].max()])),\n",
    "    tooltip = [Dimension,Measurement]\n",
    ").facet( column = Column\n",
    ").resolve_scale(x = 'independent',y = 'independent'\n",
    ")\n",
    "chart.save('chart.json')\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "# import altair_viewer\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"../test/covid19data/all_data.csv\"\n",
    "data_path = \"../test/covid19data/total_casesanddeath_by_provinces.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "Chart = alt.Chart(df).mark_bar(clip=True).encode(\n",
    "            x = alt.X(\"province\",type = \"nominal\", title= \"จังหวัด\"),\n",
    "            y = alt.Y(\"total_case\", \n",
    "                    type= \"quantitative\",\n",
    "                    scale= alt.Scale(domain=[0,df[\"total_case\"].max()]),\n",
    "                    title= \"ผู้ป่วยสะสม\"),\n",
    "            tooltip = [\"province\",\"total_case\",\"total_death\"]\n",
    "        ).facet( column = \"region\"\n",
    "        ).resolve_scale(x = 'independent',y = 'independent')\n",
    "        # self.Chart.save('ChartJSON/BarChart.json')\n",
    "Chart.save('chart.json')\n",
    "Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "import json\n",
    "\n",
    "# Load the unemployment dataset\n",
    "unemp_data = data.unemployment_across_industries()\n",
    "\n",
    "# Create an Altair line chart\n",
    "line_chart = alt.Chart(unemp_data).mark_line().encode(\n",
    "    x='month:T',\n",
    "    y='unemployment_rate:Q',\n",
    "    color='series:N'\n",
    ")\n",
    "\n",
    "chart_dict = line_chart.to_dict()\n",
    "\n",
    "# Convert any Timestamp objects to strings\n",
    "def datetime_handler(x):\n",
    "    if isinstance(x, pd.Timestamp):\n",
    "        return x.strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    raise TypeError('Unknown type')\n",
    "\n",
    "chart_dict = json.loads(json.dumps(chart_dict, default=datetime_handler))\n",
    "\n",
    "# Get the data from the original data source\n",
    "data_dict = unemp_data.to_dict(orient='records')\n",
    "\n",
    "# Update the chart dictionary to include the data\n",
    "chart_dict['datasets'] = {'unemployment_data': data_dict}\n",
    "chart_dict['data'] = {'name': 'unemployment_data'}\n",
    "\n",
    "# Save the chart dictionary to a JSON file\n",
    "with open('line_chart.json', 'w') as f:\n",
    "    json.dump(chart_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "import json\n",
    "\n",
    "# with open('Thailandprovinces.json', 'r') as f:\n",
    "#     Thaiprovince = json.load(f)\n",
    "\n",
    "data_path = \"../test/covid19data/total_cases_by_provinces.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df.drop(index=df[df[\"province\"].isin([\"All\",\"None\"])].index, inplace=True)\n",
    "# group = df.groupby('province').transform('sum')\n",
    "# df['total_case'] = group['total_case']\n",
    "# df['total_death'] = group['total_death']\n",
    "# df = df.drop_duplicates(subset=['province'])\n",
    "# Load the TopoJSON file of Thailand\n",
    "url = 'https://raw.githubusercontent.com/cvibhagool/thailand-map/master/thailand-provinces.topojson'\n",
    "topojson_data = alt.topo_feature(url, 'province')\n",
    "# provincedf = df.loc[:, ['province', 'total_case','total_death','vaccine_total_acm']]\n",
    "# provincedf['province'] = provincedf['province'].map(Thaiprovince)\n",
    "chart = alt.Chart(topojson_data).mark_geoshape().encode(\n",
    "    # color='total_case:Q',\n",
    "    color = alt.Color('total_case',type='quantitative',\n",
    "                      scale= alt.Scale(\n",
    "                        domain = [0,df['total_case'].max()],\n",
    "                        range = ['white','darkred'],\n",
    "                        type = 'linear')\n",
    "                    ),\n",
    "    tooltip = [alt.Tooltip('properties.NAME_1',type='nominal'),\n",
    "               alt.Tooltip('total_case',type='quantitative'),\n",
    "               alt.Tooltip('total_death',type='quantitative')]\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=800\n",
    ").transform_lookup(\n",
    "    lookup='properties.NAME_1',\n",
    "    from_=alt.LookupData(df, 'province', ['total_case','vaccine_total_acm','total_death'])\n",
    ")\n",
    "chart.save('chart.json')\n",
    "# chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../test/covid19data/total_cases_by_provinces.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "l = []\n",
    "for y in list(set(df['year'])):\n",
    "    maxweeknum = df.loc[df['year'] == y]['weeknum'].max()\n",
    "    l.append(df.loc[(df['weeknum'] == maxweeknum) & (df['year'] == y)])\n",
    "df = pd.concat(l, ignore_index=True)\n",
    "group = df.groupby('province').transform('sum')\n",
    "df['total_case'] = group['total_case']\n",
    "df = df.drop_duplicates(subset=['province'])\n",
    "# df.loc[df['province'] == 'Nonthaburi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    \"Amnat Charoen\": \"อำนาจเจริญ\",\n",
    "    \"Ang Thong\": \"อ่างทอง\",\n",
    "    \"Bueng Kan\": \"บึงกาฬ\",\n",
    "    \"Buri Ram\": \"บุรีรัมย์\",\n",
    "    \"Bangkok Metropolis\": \"กรุงเทพมหานคร\",\n",
    "    \"Chachoengsao\": \"ฉะเชิงเทรา\",\n",
    "    \"Chai Nat\": \"ชัยนาท\",\n",
    "    \"Chaiyaphum\": \"ชัยภูมิ\",\n",
    "    \"Chanthaburi\": \"จันทบุรี\",\n",
    "    \"Chiang Mai\": \"เชียงใหม่\",\n",
    "    \"Chiang Rai\": \"เชียงราย\",\n",
    "    \"Chon Buri\": \"ชลบุรี\",\n",
    "    \"Chumphon\": \"ชุมพร\",\n",
    "    \"Kalasin\": \"กาฬสินธุ์\",\n",
    "    \"Kamphaeng Phet\": \"กำแพงเพชร\",\n",
    "    \"Kanchanaburi\": \"กาญจนบุรี\",\n",
    "    \"Khon Kaen\": \"ขอนแก่น\",\n",
    "    \"Krabi\": \"กระบี่\",\n",
    "    \"Lampang\": \"ลำปาง\",\n",
    "    \"Lamphun\": \"ลำพูน\",\n",
    "    \"Loei\": \"เลย\",\n",
    "    \"Lop Buri\": \"ลพบุรี\",\n",
    "    \"Mae Hong Son\": \"แม่ฮ่องสอน\",\n",
    "    \"Maha Sarakham\": \"มหาสารคาม\",\n",
    "    \"Mukdahan\": \"มุกดาหาร\",\n",
    "    \"Nakhon Nayok\": \"นครนายก\",\n",
    "    \"Nakhon Pathom\": \"นครปฐม\",\n",
    "    \"Nakhon Phanom\": \"นครพนม\",\n",
    "    \"Nakhon Ratchasima\": \"นครราชสีมา\",\n",
    "    \"Nakhon Sawan\": \"นครสวรรค์\",\n",
    "    \"Nakhon Si Thammarat\": \"นครศรีธรรมราช\",\n",
    "    \"Nan\": \"น่าน\",\n",
    "    \"Narathiwat\": \"นราธิวาส\",\n",
    "    \"Nong Bua Lam Phu\": \"หนองบัวลำภู\",\n",
    "    \"Nong Khai\": \"หนองคาย\",\n",
    "    \"Nonthaburi\": \"นนทบุรี\",\n",
    "    \"Pathum Thani\": \"ปทุมธานี\",\n",
    "    \"Pattani\": \"ปัตตานี\",\n",
    "    \"Phangnga\": \"พังงา\",\n",
    "    \"Phatthalung (Songkhla Lake)\": \"พัทลุง\",\n",
    "    \"Phatthalung\":\"พัทลุง\",\n",
    "    \"Phayao\": \"พะเยา\",\n",
    "    \"Phetchabun\": \"เพชรบูรณ์\",\n",
    "    \"Phetchaburi\": \"เพชรบุรี\",\n",
    "    \"Phichit\": \"พิจิตร\",\n",
    "    \"Phitsanulok\": \"พิษณุโลก\",\n",
    "    \"Phrae\": \"แพร่\",\n",
    "    \"Phra Nakhon Si Ayutthaya\": \"พระนครศรีอยุธยา\",\n",
    "    \"Phuket\": \"ภูเก็ต\",\n",
    "    \"Prachin Buri\": \"ปราจีนบุรี\",\n",
    "    \"Prachuap Khiri Khan\": \"ประจวบคีรีขันธ์\",\n",
    "    \"Ranong\": \"ระนอง\",\n",
    "    \"Ratchaburi\": \"ราชบุรี\",\n",
    "    \"Rayong\": \"ระยอง\",\n",
    "    \"Roi Et\": \"ร้อยเอ็ด\",\n",
    "    \"Sa Kaeo\": \"สระแก้ว\",\n",
    "    \"Sakon Nakhon\": \"สกลนคร\",\n",
    "    \"Samut Prakan\": \"สมุทรปราการ\",\n",
    "    \"Samut Sakhon\": \"สมุทรสาคร\",\n",
    "    \"Samut Songkhram\": \"สมุทรสงคราม\",\n",
    "    \"Saraburi\": \"สระบุรี\",\n",
    "    \"Satun\": \"สตูล\",\n",
    "    \"Sing Buri\": \"สิงห์บุรี\",\n",
    "    \"Si Sa Ket\": \"ศรีสะเกษ\",\n",
    "    \"Songkhla\": \"สงขลา\",\n",
    "    \"Songkhla (Songkhla Lake)\": \"สงขลา\",\n",
    "    \"Sukhothai\": \"สุโขทัย\",\n",
    "    \"Suphan Buri\": \"สุพรรณบุรี\",\n",
    "    \"Surat Thani\": \"สุราษฎร์ธานี\",\n",
    "    \"Surin\": \"สุรินทร์\",\n",
    "    \"Tak\": \"ตาก\",\n",
    "    \"Trang\": \"ตรัง\",\n",
    "    \"Trat\": \"ตราด\",\n",
    "    \"Ubon Ratchathani\": \"อุบลราชธานี\",\n",
    "    \"Udon Thani\": \"อุดรธานี\",\n",
    "    \"Uthai Thani\": \"อุทัยธานี\",\n",
    "    \"Uttaradit\": \"อุตรดิตถ์\",\n",
    "    \"Yala\": \"ยะลา\",\n",
    "    \"Yasothon\": \"ยโสธร\"\n",
    "}\n",
    "\n",
    "swapped = {v: k for k, v in data.items()}\n",
    "\n",
    "with open('Thailandprovinces.json', 'w') as f:\n",
    "    json.dump(swapped, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"../test/covid19data/total_casesanddeath_by_provinces.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df['date'] = pd.to_datetime(df['year'].astype(str) + '-W' + df['weeknum'].astype(str) + '-0', format='%G-W%V-%w')\n",
    "df = df.sort_values(by=['date']).loc[df[\"province\"]==\"All\"].reset_index(drop=True)\n",
    "# df.loc[df[\"province\"]==\"All\"].head()\n",
    "df['allcase'] = 0\n",
    "df['alldeath'] = 0\n",
    "for index, row in df.iterrows():\n",
    "    if index == 0:\n",
    "        df.loc[index,'allcase'] = row['total_case']\n",
    "        casenextvalue = df.loc[index,'allcase']\n",
    "        df.loc[index,'alldeath'] = row['total_death']\n",
    "        deathnextvalue = df.loc[index,'alldeath']\n",
    "    elif index == df.shape[0] -1:\n",
    "        df.loc[index,'allcase'] = casenextvalue + row['new_case']\n",
    "        df.loc[index,'alldeath'] = deathnextvalue + row['new_death']\n",
    "    else:\n",
    "        df.loc[index,'allcase'] = casenextvalue + row['new_case']\n",
    "        casenextvalue = df.loc[index,'allcase']\n",
    "        df.loc[index,'alldeath'] = deathnextvalue + row['new_death']\n",
    "        deathnextvalue = df.loc[index,'alldeath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.Chart(df).mark_line(point=alt.OverlayMarkDef(filled=False, fill=\"white\")\n",
    "                         ).encode(\n",
    "    x=alt.X(\"date\",type=\"temporal\"),\n",
    "    y=alt.Y(\n",
    "        alt.repeat(\"layer\"), aggregate=\"mean\"),\n",
    "    tooltip = ['date:T','allcase:Q','alldeath:Q'],\n",
    "    color=alt.datum(alt.repeat(\"layer\")),\n",
    ").repeat(layer=[\"allcase\", \"alldeath\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
